{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Norzuiso/machine-learning/blob/main/FeatureSelection/manual_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "75d9e1eb",
      "metadata": {
        "id": "75d9e1eb"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras, GradientTape\n",
        "from keras import layers, Sequential\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Dense\n",
        "from tensorflow import cast, float32\n",
        "import numpy as np\n",
        "from tensorflow import losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c05f912b",
      "metadata": {
        "id": "c05f912b"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras, GradientTape\n",
        "from keras import layers, Sequential\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Dense\n",
        "from tensorflow import cast, float32\n",
        "import numpy as np\n",
        "from tensorflow import losses\n",
        "\n",
        "class GA_Weights():\n",
        "    def __init__(self, loss_fn, eval_model,\n",
        "                 crossover_std = 0.9,\n",
        "                 mutation_std = 0.2,\n",
        "                 alpha=0.1,\n",
        "                 beta=0.05,\n",
        "                 pop_size=10,\n",
        "                 generations=5):\n",
        "        self.loss_fn = loss_fn\n",
        "        self.eval_model = eval_model\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.crossover_std = crossover_std\n",
        "        self.mutation_std = mutation_std\n",
        "        self.pop_size = pop_size\n",
        "        self.generations = generations\n",
        "\n",
        "    def fitness_fn(self, individual, x, y):\n",
        "        self.eval_model.set_weights(individual)\n",
        "        y_pred = self.eval_model(x, training=False)\n",
        "        return self.loss_fn(y, y_pred)\n",
        "\n",
        "\n",
        "    # Mutacion del indivudo seleccionado desde el crossover\n",
        "    def mutate(self, individual):\n",
        "        W, b = individual\n",
        "        W = W + np.random.randn(W.shape) * self.mutation_std\n",
        "        b = b + np.random.randn(b.shape) * self.mutation_std\n",
        "        return [W, b]\n",
        "\n",
        "    def crossover(self, parent_a, parent_b):\n",
        "        Wa, ba = parent_a\n",
        "        Wb, bb = parent_b\n",
        "        return [(Wa + Wb) * 0.5, (ba + bb) * 0.5]\n",
        "\n",
        "    # Seleccion de un solo individuo por torneo\n",
        "    def tournament(self, pop, scores, k=3):\n",
        "        idx = tf.random.shuffle(tf.range(len(pop)))[:k]\n",
        "        best = idx[tf.argmin(tf.gather(scores, idx))]\n",
        "        return pop[int(best)]\n",
        "\n",
        "    def call_best_weights_GA(self, x, y):\n",
        "        idx = tf.random.shuffle(tf.range(len(x)))[: self.subset_size]\n",
        "        x = tf.gather(x, idx)\n",
        "        y = tf.gather(y, idx)\n",
        "        base_W = self.eval_model.get_weights()\n",
        "        population = [\n",
        "            [\n",
        "                base_W[0] + tf.random.normal(base_W[0].shape) * 0.1,\n",
        "                base_W[1] + tf.random.normal(base_W[1].shape) * 0.1,\n",
        "            ]\n",
        "            for _ in range(self.pop_size)\n",
        "        ]\n",
        "\n",
        "        for _ in range(self.generations):\n",
        "            fitness_scores = tf.stack([self.fitness_fn(ind, x, y) for ind in population])\n",
        "\n",
        "            new_population = [population[int(tf.argmin(fitness_scores))]]\n",
        "            while len(new_population) < self.pop_size:\n",
        "                parent_a = self.tournament_selecction(population, fitness_scores)\n",
        "                parent_b = self.tournament_selecction(population, fitness_scores)\n",
        "\n",
        "                child = self.crossover(parent_a, parent_b) if tf.random.uniform(()) < self.crossover_std else a\n",
        "                child = self.mutate(child)\n",
        "                new_population.append(child)\n",
        "\n",
        "            population = new_population\n",
        "\n",
        "        return population[int(tf.argmin(fitness_scores))]\n",
        "\n",
        "class myModel():\n",
        "    def __init__(self, feature_extractor, classifier, batch_size=32):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.classifier = classifier\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.optimizer = keras.optimizers.Adam()\n",
        "        self.loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "        self.acc_metric = keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
        "\n",
        "        self.GA_Weights = GA_Weights(\n",
        "            loss_fn=self.loss_fn,\n",
        "            eval_model=self.classifier)\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        feats = self.feature_extractor(x, training=training)\n",
        "        return self.classifier(feats, training=training)\n",
        "\n",
        "    def create_dataset(self, x, y):\n",
        "        return tf.data.Dataset.from_tensor_slices((x, y)).batch(self.batch_size)\n",
        "\n",
        "    def train_epoch(self, x, y):\n",
        "        dataset = self.create_dataset(x, y)\n",
        "\n",
        "        for xb, yd in dataset:\n",
        "            with GradientTape() as tape:\n",
        "                logits = self.call(xb)\n",
        "                loss = self.loss_fn(yd, logits)\n",
        "            gradients = tape.gradient(loss, self.feature_extractor.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.feature_extractor.trainable_variables))\n",
        "\n",
        "        features = self.feature_extractor(x, training=False)\n",
        "\n",
        "        best_weights = self.GA_Weights.call_best_weights_GA(features, y)\n",
        "        self.classifier.set_weights(best_weights)\n",
        "\n",
        "        preds = self.classifier(features, training=False)\n",
        "        self.acc_metric.update_state(y, preds)\n",
        "\n",
        "        acc = float(self.acc_metric.result())\n",
        "        self.acc_metric.reset_state()\n",
        "\n",
        "        return float(loss), acc\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        ds = tf.data.Dataset.from_tensor_slices(x).batch(self.batch_size)\n",
        "        out = []\n",
        "        for xb in ds:\n",
        "            logits = self(xb, training=False)\n",
        "            out.append(tf.argmax(logits, axis=1))\n",
        "        return tf.concat(out, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "\n",
        "cnn = Sequential([\n",
        "        layers.Input(shape = (28, 28, 1)),\n",
        "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "        layers.GlobalAveragePooling2D()\n",
        "])\n",
        "\n",
        "mlp = Dense(10, activation='softmax', name='classifier')\n",
        "\n",
        "model = myModel(cnn, mlp)\n",
        "for epoch in range(2):\n",
        "    loss, acc = model.train_epoch(x_train, y_train)\n",
        "    print(f\"Epoch {epoch+1} | loss={loss:.4f} acc={acc:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ba4d83",
      "metadata": {
        "id": "62ba4d83"
      },
      "outputs": [],
      "source": [
        "pred = training.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10368d47",
      "metadata": {
        "id": "10368d47"
      },
      "outputs": [],
      "source": [
        "def train_model(epochs, dataset, loss_fn, optimizer, feature_extractor, classifier):\n",
        "    for epoch in range(epochs):\n",
        "        with GradientTape() as tape:\n",
        "            features = feature_extractor(x, training=True)\n",
        "            preds = classifier(features, training=False)\n",
        "            loss = loss_fn(y, preds)\n",
        "        training_vars = feature_extractor.trainable_variables\n",
        "        gradients = tape.gradient(loss, training_vars)\n",
        "    optimizer.apply_gradients(zip(gradients, training_vars))\n",
        "    w = classifier.get_weights()[0]\n",
        "    print(w.shape)\n",
        "    ga_update(features.numpy(), y.numpy(), classifier)\n",
        "    print(f\"Epoch{epoch}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}