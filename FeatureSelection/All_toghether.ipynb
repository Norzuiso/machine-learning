{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9a8c5b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras, GradientTape\n",
    "from keras import layers, Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from tensorflow import cast, float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "61b228ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_32     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_78 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_79 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_32     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,816</span> (73.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,816\u001b[0m (73.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,816</span> (73.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,816\u001b[0m (73.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_32     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ classifier (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_78 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_79 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_32     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ classifier (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,466</span> (76.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,466\u001b[0m (76.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,466</span> (76.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,466\u001b[0m (76.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import Model\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape = (28, 28, 1)),\n",
    "        layers.Conv2D(64, 3, padding='same'),\n",
    "        layers.ReLU(),\n",
    "        layers.Conv2D(128, 3, padding='same'),\n",
    "        layers.ReLU(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ],\n",
    "    name = 'model'\n",
    ")\n",
    "\n",
    "cnn = Sequential([\n",
    "        layers.Input(shape = (28, 28, 1)),\n",
    "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.GlobalAveragePooling2D()\n",
    "])\n",
    "print(cnn.summary())\n",
    "\n",
    "mlp = Dense(10, activation='softmax', name='classifier')\n",
    "cnn.add(mlp)\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea285a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py:717: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 49ms/step - accuracy: 0.9665 - loss: 0.0363\n",
      "Epoch 2/2\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 50ms/step - accuracy: 0.9771 - loss: 0.0172\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9778 - loss: 6.8026e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.0006802589632570744>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9777846336364746>]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape = (28, 28, 1)),\n",
    "        layers.Conv2D(64, 3, padding='same'),\n",
    "        layers.ReLU(),\n",
    "        layers.Conv2D(128, 3, padding='same'),\n",
    "        layers.ReLU(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ],\n",
    "    name = 'model'\n",
    ")\n",
    "class CustomFit(keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(CustomFit, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def compile(self, optimizer, loss):\n",
    "        super(CustomFit, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.model(x, training=True)\n",
    "            loss = self.loss(y, y_pred)\n",
    "        training_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, training_vars)\n",
    "\n",
    "        self.optimizer.apply_gradients(zip(gradients, training_vars))\n",
    "        acc_metric.update_state(y, y_pred)\n",
    "\n",
    "        return {\"loss\" : loss, \"accuracy\": acc_metric.result()}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        y_pred = self.model(x, training=False)\n",
    "        loss = self.loss(y, y_pred)\n",
    "        acc_metric.update_state(y, y_pred)\n",
    "\n",
    "        return {\"loss\" : loss, \"accuracy\": acc_metric.result()}\n",
    "\n",
    "\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
    "\n",
    "training = CustomFit(model)\n",
    "training.compile(\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "training.fit(x_train, y_train, batch_size=32, epochs=2)\n",
    "training.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d6d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(features, labels, batch_size):\n",
    "    return tf.data.Dataset.from_tensor_slices((features, labels)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781ee0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import losses\n",
    "\n",
    "# Mutacion del indivudo seleccionado desde el crossover\n",
    "def mutate(individual, mutation_prob):\n",
    "    mutated = individual.copy()\n",
    "\n",
    "    for gene_idx in range(len(mutated)):\n",
    "        if np.random.rand() < mutation_prob:\n",
    "            mutated[gene_idx] = 1 - mutated[gene_idx]\n",
    "\n",
    "    return mutated\n",
    "\n",
    "def crossover(parent_a, parent_b):\n",
    "    gene_mask = np.random.rand(len(parent_a)) < 0.5 \n",
    "    return np.where(gene_mask, parent_a, parent_b)\n",
    "\n",
    "# Seleccion de un solo individuo por torneo\n",
    "def tournament_selecction(population, fitness_scores, tournament_size = 3):\n",
    "    candidate_indices = np.random.choice(\n",
    "        len(population),\n",
    "        size = tournament_size, \n",
    "        replace = False\n",
    "    )\n",
    "\n",
    "    candidate_fitness = fitness_scores[candidate_indices]\n",
    "    winner_index = candidate_indices[np.argmin(candidate_fitness)]\n",
    "    return population[winner_index]\n",
    "\n",
    "# No se si mi funcion fitness esta bien, pero es lo que saque con lo que pude\n",
    "# Categorical cross-entropy la agarre porque de acuerdo a google se suele usar cuando se tienen mas de dos clases y tambien porque funciona con softmax\n",
    "loss_fn = losses.CategoricalCrossentropy()\n",
    "def fitness(individual, x, y, alpha, beta, classifier_model):\n",
    "    if individual.sum() == 0:\n",
    "        return np.inf\n",
    "    individual_tf = cast(individual, float32)\n",
    "    \n",
    "    x_sel = x * individual_tf\n",
    "\n",
    "    y_pred = classifier_model(x_sel, training=False)\n",
    "\n",
    "    error = loss_fn(y, y_pred).numpy()\n",
    "        \n",
    "    return (\n",
    "        alpha * error\n",
    "        + beta * (individual.sum() / x.shape[1])\n",
    "    )\n",
    "\n",
    "\n",
    "def genetic_algorithm(x, y, classifier_model, pop_size=40, generations=10,\n",
    "                      crossover_prob = 0.9,\n",
    "                      mutation_prob = 0.2,\n",
    "                      alpha=0.1, \n",
    "                      beta=0.05):\n",
    "    best_individual = None\n",
    "    best_fitness = np.inf\n",
    "    best_fitness_history = []\n",
    "    fitness_scores_history = []\n",
    "    \n",
    "    num_features = x.shape[1]\n",
    "    # Inicializamos la poblacion \n",
    "    population = np.random.randint(0, 2, size=(pop_size, num_features))\n",
    "    for generation_idx in range(generations):\n",
    "        # Fitness Evaluation para toda la poblacion\n",
    "        fitness_scores = np.array([\n",
    "            fitness(individual, x, y, alpha, beta, classifier_model) for individual in population \n",
    "        ])\n",
    "        # Seleccionamos el mejor individuo\n",
    "        best_index_in_population = np.argmin(fitness_scores)\n",
    "        \n",
    "        # Si el fitness del mejor individuo es mejor que el best_fitness actual\n",
    "        if fitness_scores[best_index_in_population] < best_fitness:\n",
    "        # Actualizamos el mejor fitness y el mejor individuo\n",
    "            best_fitness = fitness_scores[best_index_in_population]\n",
    "            best_individual = population[best_index_in_population].copy()\n",
    "        \n",
    "        new_population = []\n",
    "\n",
    "        # Seleccionamos los parents\n",
    "        if np.random.rand() < 0.5:\n",
    "            new_population.append(best_individual.copy())\n",
    "        \n",
    "        while len(new_population) < pop_size:\n",
    "            parent_a = tournament_selecction(population, fitness_scores)\n",
    "            parent_b = tournament_selecction(population, fitness_scores)\n",
    "\n",
    "            if np.random.rand() < crossover_prob:\n",
    "                individual = crossover(parent_a, parent_b)\n",
    "            else:\n",
    "                individual = parent_a.copy()\n",
    "            \n",
    "            individual = mutate(individual, mutation_prob)\n",
    "\n",
    "            new_population.append(individual)\n",
    "        population = np.array(new_population)\n",
    "\n",
    "        print(f\"Gen {generation_idx:02d}\")\n",
    "        print(f\"Fitness {best_fitness:.4f}\")\n",
    "        print(f\"Features  {best_individual.sum()}\")\n",
    "        print(f\"Mean cost: {fitness_scores.mean():.4f}\")\n",
    "        print(f\"Std cost: {fitness_scores.std():.6f}\")\n",
    "        best_fitness_history.append(best_fitness)\n",
    "        fitness_scores_history.append(fitness_scores)\n",
    "    return best_individual, best_fitness\n",
    "\n",
    "# Simple GA for Dense weights\n",
    "def ga_update(features, labels, dense_layer, pop_size=8, generations=10):\n",
    "    W, b = dense_layer.get_weights()\n",
    "    pop = [(W + np.random.randn(*W.shape)*0.1,\n",
    "            b + np.random.randn(*b.shape)*0.1)\n",
    "           for _ in range(pop_size)]\n",
    "\n",
    "    best_loss = 1e9\n",
    "    best = (W, b)\n",
    "\n",
    "    for Wi, bi in pop:\n",
    "        dense_layer.set_weights([Wi, bi])\n",
    "        preds = dense_layer(features, training=False)\n",
    "        l = loss_fn(labels, preds).numpy()\n",
    "        if l < best_loss:\n",
    "            best_loss = l\n",
    "            best = (Wi, bi)\n",
    "    dense_layer.set_weights(best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a033cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, dataset, loss_fn, optimizer, feature_extractor, classifier):\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in dataset:\n",
    "            with GradientTape() as tape:\n",
    "                features = feature_extractor(x, training=True)\n",
    "                preds = classifier(features, training=False)\n",
    "                loss = loss_fn(y, preds)\n",
    "            training_vars = feature_extractor.trainable_variables\n",
    "            gradients = tape.gradient(loss, training_vars)\n",
    "            optimizer.apply_gradients(zip(gradients, training_vars))\n",
    "            w = classifier.get_weights()[0]\n",
    "            print(w.shape)\n",
    "            ga_update(features.numpy(), y.numpy(), classifier)\n",
    "        print(f\"Epoch{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "21d57d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "(imgs_train, labels_train), (imgs_test, labels_test) = mnist.load_data()\n",
    "\n",
    "imgs_train = imgs_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "imgs_test = imgs_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "\n",
    "# Modelos\n",
    "cnn = Sequential([\n",
    "        layers.Input(shape = (28, 28, 1)),\n",
    "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.GlobalAveragePooling2D()\n",
    "])\n",
    "\n",
    "mlp = Dense(10, activation='softmax', name='classifier')\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "batch_size = 5000\n",
    "epochs = 1\n",
    "dataset = create_dataset(imgs_train, labels_train, batch_size)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4df4aacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "Epoch0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 05:46:57.864809: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "train_model(epochs, dataset, loss_fn, optimizer, cnn, mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "435df802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2278f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
